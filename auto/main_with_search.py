"""
ë¦¬ë·° ë¸”ë¡œê·¸ ìë™í™” ì‹œìŠ¤í…œ (ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨)
LangGraphì™€ ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•œ ë¸”ë¡œê·¸ ê´€ë¦¬ ìë™í™”
"""

import os
from typing import TypedDict, List, Dict
from datetime import datetime
from dotenv import load_dotenv
import uuid
import json

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, SystemMessage
from config import get_llm
from search_tools import WebSearcher, format_search_results
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
from io import BytesIO
from PIL import Image
import hashlib
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(verbose=True, override=True)


# LLM ì„¤ì •
# llm ë™ì  ì„ íƒ: OPENAI_API_KEY > GOOGLE_API_KEY > ë¡œì»¬
def choose_llm():
    # Gemini ìš°ì„ 
    if os.getenv("GOOGLE_API_KEY"):
        return get_llm("gemini-2.5-flash", temperature=0.5)
    if os.getenv("OPENAI_API_KEY"):
        return get_llm("gpt-4o-mini", temperature=0.5)
    return get_llm("gpt-oss", temperature=0.7)


llm = choose_llm()

# ì›¹ ê²€ìƒ‰ ë„êµ¬
searcher = WebSearcher()

# ìƒì„±ëœ ë¦¬ë·° ì¶”ì  íŒŒì¼ ê²½ë¡œ ë° ê²½ë¡œ ìƒìˆ˜
GENERATED_REVIEWS_FILE = "generated_reviews.json"
ROOT_DIR = os.path.dirname(os.path.dirname(__file__))
POSTS_DIR = os.path.join(ROOT_DIR, "app", "posts")
IMAGES_DIR = os.path.join(ROOT_DIR, "app", "public", "images")


# ìƒíƒœ ì •ì˜
class BlogState(TypedDict):
    task: str
    product_name: str
    search_results: Dict
    posts: List[dict]
    current_post: dict
    feedback: str
    completed: bool
    images: List[dict]
    product_slug: str
    local_images: List[dict]


# ì‚¬ëŒìŠ¤ëŸ¬ìš´ ë¦¬ë·° ìŠ¤íƒ€ì¼ ê°€ì´ë“œ (MX Master 4 ì‹¤ì‚¬ìš© í›„ê¸° ìŠ¤íƒ€ì¼ ì°¸ê³ )
HUMAN_REVIEW_STYLE_GUIDE = """
- 1ì¸ì¹­ ì‹œì (â€˜ì €ëŠ”â€™, â€˜ì œ ê¸°ì¤€ì—ì„œëŠ”â€™)ìœ¼ë¡œ, ì‹¤ì œë¡œ ì¨ ë³¸ ì‚¬ëŒì˜ ë¸”ë¡œê·¸ í›„ê¸°ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì”ë‹ˆë‹¤.
- ë¨¼ì € â€œì™œ ì´ ì œí’ˆì„ ì•Œì•„ë³´ê²Œ ë˜ì—ˆëŠ”ì§€/ì‚¬ê²Œ ë˜ì—ˆëŠ”ì§€â€ì™€ í˜„ì¬ ì‚¬ìš© í™˜ê²½(ì‚¬ìš© ê¸°ê°„, ì‚¬ìš©í•˜ëŠ” ê¸°ê¸° ì¡°í•©, ì£¼ìš” ì‘ì—…)ì„ 1~2ë‹¨ë½ìœ¼ë¡œ í’€ì–´ì¤ë‹ˆë‹¤.
- ì¥ì /ë‹¨ì ì€ ìŠ¤í™ ë‚˜ì—´ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ìƒí™©ì—ì„œ ë¬´ì—‡ì´ ì–´ë–»ê²Œ í¸í–ˆëŠ”ì§€Â·ì•„ì‰¬ì› ëŠ”ì§€ë¥¼ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.
- ê°œë°œ/ì—…ë¬´/ì˜ìƒ í¸ì§‘/ì¼ìƒ ë“± ì‹¤ì œ ì‘ì—… íë¦„ ì†ì—ì„œ ì–´ë–¤ ë¶€ë¶„ì´ ì²´ê°ë˜ëŠ”ì§€ ì´ì•¼ê¸°ë¥¼ ì„ì–´ ì¤ë‹ˆë‹¤.
- ê°€ê²©, ë¬´ê²Œ, íœ´ëŒ€ì„±, ì† í¬ê¸°Â·ì‚¬ìš© ìŠµê´€ì²˜ëŸ¼ ì‚¬ëŒë§ˆë‹¤ ê°ˆë¦´ ìˆ˜ ìˆëŠ” í¬ì¸íŠ¸ëŠ” ì¥ë‹¨ì  ì–‘ìª½ì—ì„œ ê· í˜• ìˆê²Œ ë‹¤ë£¹ë‹ˆë‹¤.
- ë§ˆì§€ë§‰ì—ëŠ” â€œì´ëŸ° ì‚¬ëŒì—ê²Œ ì¶”ì²œ / ì´ëŸ° ì‚¬ëŒì—ê²ŒëŠ” êµ³ì´ í•„ìš” ì—†ìŒâ€ì„ ì •ë¦¬í•˜ê³ , í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì´í‰ì„ ë‚¨ê¹ë‹ˆë‹¤.
- ê³¼ì¥ëœ ê´‘ê³  ë¬¸êµ¬ë³´ë‹¤ëŠ” ë‹´ë°±í•˜ê³  ì†”ì§í•œ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ë‹¤ë§Œ, ëª¨ë¸ì´ ì‹¤ì œë¡œ ì œí’ˆì„ ì‚¬ìš©í•œ ê²ƒì²˜ëŸ¼ ë‹¨ì •ì ìœ¼ë¡œ ë§í•˜ì§„ ë§ê³ ,
  â€˜ì—¬ëŸ¬ í›„ê¸°ë“¤ì„ ë³´ë©´â€™, â€˜ì‹¤ì‚¬ìš© í›„ê¸°ë¥¼ ì¢…í•©í•˜ë©´â€™, â€˜ì œ ê¸°ì¤€ì—ì„œë¼ë©´ ì´ëŸ° ë¶€ë¶„ì´ ê°€ì¥ ë¨¼ì € ëˆˆì— ë“¤ì–´ì˜¬ ê²ƒ ê°™ìŠµë‹ˆë‹¤â€™ì²˜ëŸ¼ í‘œí˜„í•©ë‹ˆë‹¤.
"""


# ë¦¬ë·° ì¶”ì  í•¨ìˆ˜ë“¤
def load_generated_reviews() -> List[Dict]:
    """ìƒì„±ëœ ë¦¬ë·° ëª©ë¡ ë¡œë“œ"""
    try:
        if os.path.exists(GENERATED_REVIEWS_FILE):
            with open(GENERATED_REVIEWS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception as e:
        print(f"âš ï¸ ë¦¬ë·° ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return []


def save_generated_reviews(reviews: List[Dict]) -> None:
    """ìƒì„±ëœ ë¦¬ë·° ëª©ë¡ ì €ì¥"""
    try:
        with open(GENERATED_REVIEWS_FILE, "w", encoding="utf-8") as f:
            json.dump(reviews, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ ë¦¬ë·° ëª©ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")


def is_product_already_reviewed(product_name: str) -> bool:
    """ì œí’ˆì´ ì´ë¯¸ ë¦¬ë·°ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    reviews = load_generated_reviews()
    normalized_product = product_name.lower().strip()

    for review in reviews:
        existing_product = review.get("product_name", "").lower().strip()
        if (
            normalized_product in existing_product
            or existing_product in normalized_product
        ):
            return True
    return False


def add_review_record(product_name: str, filename: str) -> None:
    """ìƒˆ ë¦¬ë·° ê¸°ë¡ ì¶”ê°€"""
    reviews = load_generated_reviews()
    new_review = {
        "product_name": product_name,
        "filename": filename,
        "created_at": datetime.now().isoformat(),
        "timestamp": datetime.now().timestamp(),
    }
    reviews.append(new_review)
    save_generated_reviews(reviews)
    print(f"ğŸ“ ë¦¬ë·° ê¸°ë¡ ì¶”ê°€: {product_name} -> {filename}")


# ë…¸ë“œ í•¨ìˆ˜ë“¤
STYLE_REF_PATTERN = re.compile(
    r"@(?P<filename>[^\s]+)\s*\((?P<start>\d+)\s*-\s*(?P<end>\d+)\)"
)


def extract_style_reference(task: str) -> Dict[str, str]:
    """íƒœìŠ¤í¬ ë¬¸ìì—´ì—ì„œ @íŒŒì¼ëª… (1-276) í˜•íƒœì˜ ìŠ¤íƒ€ì¼ ì°¸ì¡° ì •ë³´ ì¶”ì¶œ"""
    if not task:
        return {}
    match = STYLE_REF_PATTERN.search(task)
    if not match:
        return {}
    return {
        "style_file": match.group("filename"),
        "style_range": f"{match.group('start')}-{match.group('end')}",
        "style_hint": "example_review",
    }


def strip_style_reference(task: str) -> str:
    """íƒœìŠ¤í¬ ë¬¸ìì—´ì—ì„œ ìŠ¤íƒ€ì¼ ì°¸ì¡° í‘œê¸° ì œê±°"""
    if not task:
        return ""
    return STYLE_REF_PATTERN.sub("", task).strip()


def analyze_task(state: BlogState) -> BlogState:
    """ì‘ì—… ë¶„ì„ ë° ì œí’ˆëª… ì¶”ì¶œ"""
    task = state.get("task", "")

    print(f"ğŸ“‹ ì‘ì—… ë¶„ì„ ì¤‘: {task}")

    # ìŠ¤íƒ€ì¼ ì°¸ì¡° ì •ë³´ ì¶”ì¶œ (@review-mx-master-4-ddc17c.md (1-276) í˜•íƒœ)
    style_ref = extract_style_reference(task)
    if style_ref:
        state["style_reference"] = style_ref

    # ìŠ¤íƒ€ì¼ ì°¸ì¡° í‘œê¸°ëŠ” ì œí’ˆëª… ë¶„ì„ ëŒ€ìƒì—ì„œ ì œê±°
    task_for_product = strip_style_reference(task)

    # ì œí’ˆëª… ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NERì´ë‚˜ íŒ¨í„´ ë§¤ì¹­ ì‚¬ìš©
    product_keywords = [
        "ì—ì–´íŒŸ",
        "ê°¤ëŸ­ì‹œ",
        "ì•„ì´í°",
        "ë§¥ë¶",
        "ì• í”Œì›Œì¹˜",
        "ë‹¤ì´ìŠ¨",
        "LG",
        "ì‚¼ì„±",
    ]

    product_name = ""
    # MX Master ê°™ì€ ì œí’ˆë„ ì¡°ê¸ˆ ë” ì˜ ì¡ë„ë¡ ë²”ìš© í‚¤ì›Œë“œ ì¶”ê°€
    product_keywords.extend(["ë¡œì§€í…", "ë¡œì§€í… MX", "MX", "ë§ˆìŠ¤í„°"])

    for keyword in product_keywords:
        if keyword in task_for_product:
            # ì „ì²´ ì œí’ˆëª… ì¶”ì¶œ ì‹œë„
            words = task_for_product.split()
            for i, word in enumerate(words):
                if keyword in word:
                    # ì£¼ë³€ ë‹¨ì–´ë“¤ë„ í¬í•¨
                    start = max(0, i - 1)
                    end = min(len(words), i + 3)
                    product_name = " ".join(words[start:end])
                    break
            if product_name:
                break

    if not product_name:
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì „ì²´ íƒœìŠ¤í¬(ìŠ¤íƒ€ì¼ ì°¸ì¡° ì œê±°ë³¸) ì‚¬ìš©
        product_name = (
            task_for_product.replace("ë¦¬ë·°", "").replace("ì‘ì„±", "").strip()
        )

    state["product_name"] = product_name
    state["product_slug"] = slugify(product_name)
    state["current_post"] = {"type": "review", "status": "analyzing"}

    print(f"ğŸ¯ ì¶”ì¶œëœ ì œí’ˆëª…: {product_name}")

    # ì¤‘ë³µ ì²´í¬
    if os.getenv("FORCE_REGENERATE") != "1" and is_product_already_reviewed(
        product_name
    ):
        print(f"âš ï¸ '{product_name}' ì œí’ˆì€ ì´ë¯¸ ë¦¬ë·°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤!")
        state["current_post"]["status"] = "duplicate"
        state["completed"] = True
        return state

    return state


def research_product(state: BlogState) -> BlogState:
    """ì œí’ˆ ì •ë³´ ë¦¬ì„œì¹˜ ë…¸ë“œ (ì›¹ ê²€ìƒ‰)"""
    product_name = state.get("product_name", "")

    print(f"ğŸ” ì œí’ˆ ì •ë³´ ë¦¬ì„œì¹˜ ì¤‘: {product_name}")

    # í™˜ê²½ë³€ìˆ˜ë¡œ ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™” (ìƒŒë“œë°•ìŠ¤/ë„¤íŠ¸ì›Œí¬ ì œí•œ íšŒí”¼)
    if os.getenv("DISABLE_WEB_SEARCH") == "1":
        print("âš™ï¸  ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™”ë¨(DISABLE_WEB_SEARCH=1). ê²€ìƒ‰ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        state["search_results"] = {
            "product": product_name,
            "latest_product": product_name,
            "basic_info": [],
            "price_info": [],
            "recent_news": [],
            "user_reviews": [],
            "images": [],
        }
        return state

    # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
    search_results = searcher.get_comprehensive_info(product_name)
    state["search_results"] = search_results

    # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    total_results = (
        len(search_results.get("basic_info", []))
        + len(search_results.get("price_info", []))
        + len(search_results.get("recent_news", []))
        + len(search_results.get("user_reviews", []))
        + len(search_results.get("images", []))
    )

    print(f"âœ… ì´ {total_results}ê°œì˜ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")

    return state


def collect_images(state: BlogState) -> BlogState:
    """ì œí’ˆ ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ ë…¸ë“œ (ë‹¤ìš´ë¡œë“œ ì—†ì´ ë§í¬ë§Œ)"""
    product_name = state.get("product_name", "")
    search_results = state.get("search_results", {})

    print(f"ğŸ–¼ï¸ ì œí’ˆ ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ ì¤‘: {product_name}")

    if os.getenv("DISABLE_WEB_SEARCH") == "1":
        print("âš™ï¸  ì›¹ ê²€ìƒ‰ ë¹„í™œì„±í™” ìƒíƒœ: ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ ê±´ë„ˆëœ€")
        state["images"] = []
        return state

    # ê²€ìƒ‰ëœ ì´ë¯¸ì§€ë“¤
    images = search_results.get("images", [])

    if images:
        # ìµœì‹  ì´ë¯¸ì§€ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒ
        recent_images = [img for img in images if img.get("is_recent", False)]
        normal_images = [img for img in images if not img.get("is_recent", False)]

        # ìµœì‹  ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ìµœì‹  ì´ë¯¸ì§€ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ ì´ë¯¸ì§€ ì‚¬ìš©
        priority_images = recent_images + normal_images

        print(
            f"ğŸ“Š ì´ë¯¸ì§€ ìš°ì„ ìˆœìœ„: ìµœì‹  ì´ë¯¸ì§€ {len(recent_images)}ê°œ, ì¼ë°˜ ì´ë¯¸ì§€ {len(normal_images)}ê°œ"
        )

        # ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ ì‹¤í–‰ (ë‹¤ìš´ë¡œë“œ ì—†ì´)
        image_info_list = searcher.get_product_images_info(
            product_name, priority_images, max_images=4
        )
        state["images"] = image_info_list
        print(f"âœ… {len(image_info_list)}ê°œ ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ (ë§í¬ë§Œ)")

        # ì´ë¯¸ì§€ ì¶œì²˜ ì •ë³´ ë¡œê¹… (ìƒì„¸íˆ)
        for i, img_info in enumerate(image_info_list):
            is_recent = "ìµœì‹ " if priority_images[i].get("is_recent") else "ì¼ë°˜"
            url = img_info["url"].lower()

            # ì´ë¯¸ì§€ í˜•ì‹ê³¼ í˜¸ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
            if url.endswith(".webp"):
                format_info = "WebP"
            elif url.endswith(".jpg") or url.endswith(".jpeg"):
                format_info = "JPG"
            elif url.endswith(".png"):
                format_info = "PNG"
            else:
                format_info = "ê¸°íƒ€"

            # CDN ì •ë³´ í™•ì¸
            cdn_info = ""
            fast_hosts = [
                "cloudinary",
                "imgur",
                "cdn",
                "fastly",
                "akamai",
                "googleusercontent",
                "githubusercontent",
                "amazonaws",
            ]
            for host in fast_hosts:
                if host in url:
                    cdn_info = f"CDN:{host}"
                    break

            print(
                f"  {i+1}. {img_info['title']} ({is_recent}, {format_info}, {cdn_info})"
            )
    else:
        print(f"âš ï¸ ìˆ˜ì§‘í•  ì´ë¯¸ì§€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        state["images"] = []

    return state


def generate_content(state: BlogState) -> BlogState:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ì¸  ìƒì„±"""
    task = state.get("task", "")
    product_name = state.get("product_name", "")
    search_results = state.get("search_results", {})

    print(f"âœï¸ ê²€ìƒ‰ ê¸°ë°˜ ì»¨í…ì¸  ìƒì„± ì¤‘...")

    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    context = format_search_context(search_results)

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œì˜ ì²˜ë¦¬
    if not context.strip():
        print(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì •ë³´ë¡œ ì»¨í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        context = f"""
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ì—ˆì§€ë§Œ, {product_name}ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ë¦¬ë·°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
        ì œí’ˆì˜ ì¼ë°˜ì ì¸ íŠ¹ì§•ê³¼ ì‚¬ìš©ìë“¤ì´ ìì£¼ ì–¸ê¸‰í•˜ëŠ” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¦¬ë·°ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.
        """

    # LLMì„ ì‚¬ìš©í•´ ì»¨í…ì¸  ìƒì„± (ì‚¬ëŒì´ ì“´ í›„ê¸° ê°™ì€ í†¤ + í’ˆì§ˆ ê·œê²©)
    style_ref = state.get("style_reference", {}) or {}
    style_note = ""
    if style_ref.get("style_hint") == "example_review":
        # ì‚¬ìš©ìê°€ @review-... (1-276) í˜•íƒœë¡œ ìŠ¤íƒ€ì¼ ì˜ˆì‹œë¥¼ ì§€ì •í•œ ê²½ìš°
        style_note = """
        ì¶”ê°€ ìŠ¤íƒ€ì¼ íŒíŠ¸:
        - ì‚¬ìš©ìê°€ ì§€ì •í•œ ì˜ˆì‹œ ë¦¬ë·°ì²˜ëŸ¼,
          "êµ¬ì… ë°°ê²½ â†’ ì‚¬ìš© í™˜ê²½ â†’ ì¥ì /ë‹¨ì  â†’ ë¹„êµ â†’ ì¶”ì²œ/ë¹„ì¶”ì²œ â†’ ì´í‰" íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•˜ì„¸ìš”.
        """

    system_prompt = f"""
    ë‹¹ì‹ ì€ ë¦¬ë·° ë¸”ë¡œê·¸ 'ë¦¬ë·° í™œì§'ì˜ ë©”ì¸ í•„ì§„ì…ë‹ˆë‹¤.
    ì•„ë˜ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ë”°ë¼, ì‚¬ëŒì´ ì§ì ‘ ì¨ ë‚´ë ¤ê°„ ê²ƒ ê°™ì€ í•œêµ­ì–´ ë¦¬ë·°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    [ìŠ¤íƒ€ì¼ ê°€ì´ë“œ]
    {HUMAN_REVIEW_STYLE_GUIDE}
    {style_note}

    ì‘ì„± ê·œì¹™:
    - ì „ì²´ ë¶„ëŸ‰ì€ ìµœì†Œ 1,500ì ì´ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.
    - ë¬¸ë‹¨ë§ˆë‹¤ êµ¬ì²´ì ì¸ ìƒí™©(ì–´ë–¤ í™˜ê²½, ì–´ë–¤ ì‘ì—…, ì–´ë–¤ ìœ í˜•ì˜ ì‚¬ìš©ì)ì„ ìƒìƒí•´ì„œ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”.
    - ë„ˆë¬´ ë”±ë”±í•œ ê¸°ìˆ  ë¬¸ì„œ ëŠë‚Œì´ ì•„ë‹ˆë¼, ë¸”ë¡œê·¸ì— ì˜¬ë¦¬ëŠ” ê¸´ í›„ê¸° ëŠë‚Œìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    êµ¬ì¡°(í—¤ë”©ì€ ë°˜ë“œì‹œ ì´ ì´ë¦„ì„ ì‚¬ìš©):
    ### ì œí’ˆ ì†Œê°œ & êµ¬ì… ë°°ê²½
    ### ì‚¬ìš© í™˜ê²½ ì •ë¦¬
    ### ì¥ì 
    - 3ê°€ì§€ ì´ìƒ, ê°ê° 2ë¬¸ì¥ ì´ìƒ
    ### ë‹¨ì 
    - 2ê°€ì§€ ì´ìƒ, ê°ê° 2ë¬¸ì¥ ì´ìƒ
    ### ê²½ìŸ ì œí’ˆ ë¹„êµ
    - ìµœì†Œ 2ê°œ ì œí’ˆê³¼ í‘œ(ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”) ë˜ëŠ” ë¶ˆë¦¿ ë¹„êµ (ì°¨ì´ì /ëŒ€ìƒ)
    ### ê°€ê²© ë° êµ¬ë§¤ íŒ
    ### FAQ
    - ìµœì†Œ 4ê°œ ì§ˆë¬¸/ë‹µë³€ (ê° 2ë¬¸ì¥ ì´ìƒ)
    ### ì´í‰ ë° ì¶”ì²œ ëŒ€ìƒ

    ì¤‘ìš”:
    - ê³µê°œëœ ì •ë³´ì™€ ë‹¤ìˆ˜ ì‚¬ìš©ì í›„ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì“°ë˜,
      ëª¨ë¸ì´ ì‹¤ì œë¡œ ì œí’ˆì„ ì‚¬ìš©í–ˆë‹¤ê³  ë‹¨ì •í•˜ëŠ” í‘œí˜„(ì˜ˆ: "ì œê°€ 3ì£¼ ë™ì•ˆ ì§ì ‘ ì¨ë³´ë‹ˆ")ì€ í”¼í•˜ì„¸ìš”.
    - ëŒ€ì‹  "ì—¬ëŸ¬ í›„ê¸°ë“¤ì„ ë³´ë©´", "ì‹¤ì‚¬ìš© í›„ê¸°ë¥¼ ì¢…í•©í•˜ë©´", "ì œ ê¸°ì¤€ì—ì„œë¼ë©´ ì´ëŸ° ë¶€ë¶„ì´ ë¨¼ì € ëˆˆì— ë“¤ì–´ì˜µë‹ˆë‹¤"ì²˜ëŸ¼ í‘œí˜„í•´ ì£¼ì„¸ìš”.
    - ë§ˆì¼€íŒ… ë¬¸êµ¬ë³´ë‹¤ëŠ” ì†”ì§í•œ ì¥ë‹¨ì ê³¼ ëˆ„ê°€ ì“¸ ë•Œ ì¢‹ì€ì§€ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
    """

    cleaned_task = strip_style_reference(task)
    if not cleaned_task:
        cleaned_task = f"{product_name}ì— ëŒ€í•œ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”."

    user_prompt = f"""
    ì œí’ˆ: {product_name}

    ë‹¹ì‹ ì˜ ì—­í• :
    - ìœ„ ì œí’ˆì— ëŒ€í•´, ì›¹ì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´ì™€ ì‚¬ìš©ì í›„ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ
      ë¸”ë¡œê·¸ 'ë¦¬ë·° í™œì§'ì— ì˜¬ë¼ê°ˆ ì¥ë¬¸ ë¦¬ë·°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

    ìˆ˜ì§‘ëœ ì •ë³´ ìš”ì•½:
    {context}

    ê¸€ì˜ ëª©ì :
    - {cleaned_task}
    """

    # ë„¤íŠ¸ì›Œí¬/í‚¤ ë¯¸ì œê³µ ì‹œ LLM ë¹„í™œì„±í™” ëª¨ë“œ ì§€ì›
    if os.getenv("DISABLE_LLM") == "1":
        content_text = generate_template_content(product_name)
    else:
        # í’ˆì§ˆ ê²Œì´íŠ¸ë¥¼ ë§Œì¡±í•  ë•Œê¹Œì§€ ìµœëŒ€ 3íšŒ ì¬ìƒì„±
        attempts = 0
        content_text = ""
        while attempts < 3:
            response = llm.invoke(
                [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt),
                ]
            )
            raw = response.content if hasattr(response, "content") else response
            content_text = to_plain_text(raw)
            if passes_quality_gates(content_text):
                break
            attempts += 1

    state["current_post"]["content"] = content_text
    state["current_post"]["status"] = "generated"
    state["current_post"]["created_at"] = datetime.now().isoformat()
    state["current_post"]["sources"] = search_results  # ì¶œì²˜ ì €ì¥

    return state


def format_search_context(search_results: Dict) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    context = ""

    # ê¸°ë³¸ ì •ë³´
    if search_results.get("basic_info"):
        context += "### ì œí’ˆ ì •ë³´:\n"
        for info in search_results["basic_info"][:3]:
            context += f"- {info['title']}: {info['body'][:200]}\n"

    # ê°€ê²© ì •ë³´
    if search_results.get("price_info"):
        context += "\n### ê°€ê²© ì •ë³´:\n"
        for price in search_results["price_info"]:
            context += f"- {price['description'][:100]}\n"

    # ì‚¬ìš©ì ë¦¬ë·°
    if search_results.get("user_reviews"):
        context += "\n### ì‚¬ìš©ì ì˜ê²¬:\n"
        for review in search_results["user_reviews"][:3]:
            context += f"- {review['summary'][:150]}\n"

    # ìµœì‹  ë‰´ìŠ¤
    if search_results.get("recent_news"):
        context += "\n### ìµœê·¼ ì†Œì‹:\n"
        for news in search_results["recent_news"][:2]:
            context += f"- {news['title']}: {news['body'][:100]}\n"

    return context


def create_markdown(state: BlogState) -> BlogState:
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± (ë¡œì»¬ ì´ë¯¸ì§€ ì‚¬ìš©)"""
    current_post = state.get("current_post", {})
    content = current_post.get("content", "")
    product_name = state.get("product_name", "")
    search_results = state.get("search_results", {})
    images = state.get("images", [])

    print(f"ğŸ“ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± ì¤‘...")

    # ë¦¬ë·° ë‚´ìš©ì„ ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆ„ê¸°
    sections = split_content_into_sections(content)
    print(f"ğŸ“Š ë¦¬ë·° ì„¹ì…˜ ìˆ˜: {len(sections)}")

    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ â†’ WebP ì €ì¥ â†’ ë¡œì»¬ ê²½ë¡œ ì‚½ì…
    local_images = download_and_prepare_images(
        state.get("product_slug", slugify(product_name)), images
    )
    state["local_images"] = local_images
    content_with_images = insert_local_images_between_sections(sections, local_images)

    # ì°¸ê³  ë§í¬ ìƒì„±
    references = "\n\n## ì°¸ê³  ìë£Œ\n\n"
    if search_results.get("basic_info"):
        for info in search_results["basic_info"][:3]:
            references += f"- [{info['title']}]({info['url']})\n"

    # ì´ë¯¸ì§€ ì¶œì²˜ëŠ” ìº¡ì…˜ìœ¼ë¡œ ì¶©ë¶„, ë³„ë„ ëª©ë¡ ìƒëµ

    # ì œí’ˆëª…ì„ ì˜ì–´ë¡œ ë³€í™˜ (íƒœê·¸ìš©)
    safe_product_name = translate_product_name_for_tags(product_name)

    # ë§ˆí¬ë‹¤ìš´ í¬ë§·ìœ¼ë¡œ ë³€í™˜
    if state.get("local_images"):
        # ì²« ë²ˆì§¸ ë¡œì»¬ ì´ë¯¸ì§€ ì‚¬ìš©
        primary_image = state["local_images"][0]["path"]
        primary_image_alt = state["local_images"][0]["alt"]
    else:
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        primary_image = "/images/product-1.webp"
        primary_image_alt = f"{product_name} ì œí’ˆ ì´ë¯¸ì§€"

    # ìë™ìƒì„± ë¬¸êµ¬ ì œê±°
    image_credit = ""

    # YAML-safe image_alt (ì´ëª¨ì§€, íŠ¹ìˆ˜ë¬¸ì, ... ë“± ì œê±°)
    safe_image_alt = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£:,.\-]', '', primary_image_alt)
    safe_image_alt = safe_image_alt.replace('...', '').replace('..', '.').strip()
    # ë„ˆë¬´ ê¸¸ë©´ 100ìë¡œ ì œí•œ
    if len(safe_image_alt) > 100:
        safe_image_alt = safe_image_alt[:100].strip()

    markdown_template = f"""---
title: '{build_unique_title(product_name)}'
date: '{datetime.now().strftime("%Y-%m-%d")}'
updated: '{datetime.now().strftime("%Y-%m-%d")}'
author: 'ë¦¬ë·° í™œì§'
excerpt: '{build_excerpt(product_name)}'
category: 'ì œí’ˆë¦¬ë·°'
tags: ['{safe_product_name}', 'ë¦¬ë·°']
image: '{primary_image}'
image_alt: '{safe_image_alt}'
rating: {estimate_rating_from_content(content)}
noindex: false
---

{content_with_images}

{image_credit}

{references}
"""

    state["current_post"]["markdown"] = markdown_template
    state["current_post"]["status"] = "markdown_created"

    return state


def translate_product_name_for_tags(product_name: str) -> str:
    """
    ì œí’ˆëª…ì„ íƒœê·¸ìš© ì˜ì–´ë¡œ ë³€í™˜

    Args:
        product_name: í•œê¸€ ì œí’ˆëª…

    Returns:
        ì˜ì–´ íƒœê·¸ëª…
    """
    # í•œê¸€ ì œí’ˆëª…ì„ ì˜ì–´ë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    korean_to_english = {
        # ì‚¼ì„± ì œí’ˆ
        "ê°¤ëŸ­ì‹œ": "galaxy",
        "ê°¤ëŸ­ì‹œ s": "galaxy-s",
        "ê°¤ëŸ­ì‹œs": "galaxy-s",
        "ê°¤ëŸ­ì‹œ s24": "galaxy-s24",
        "ê°¤ëŸ­ì‹œs24": "galaxy-s24",
        "ê°¤ëŸ­ì‹œ s25": "galaxy-s25",
        "ê°¤ëŸ­ì‹œs25": "galaxy-s25",
        "ê°¤ëŸ­ í´ë“œ": "galaxy-fold",
        "ê°¤ëŸ­í´ë“œ": "galaxy-fold",
        "ê°¤ëŸ­í´ë“œ7": "galaxy-fold7",
        "ë²„ì¦ˆ í”„ë¡œ": "buds-pro",
        "ë²„ì¦ˆí”„ë¡œ": "buds-pro",
        "ë²„ì¦ˆí”„ë¡œ3": "buds-pro3",
        # ì• í”Œ ì œí’ˆ
        "ì•„ì´í°": "iphone",
        "ì•„ì´í° 16": "iphone-16",
        "ì•„ì´í°16": "iphone-16",
        "ì•„ì´í° 16 í”„ë¡œ": "iphone-16-pro",
        "ì•„ì´í°16í”„ë¡œ": "iphone-16-pro",
        "ì•„ì´í° 16 í”„ë¡œ ë§¥ìŠ¤": "iphone-16-pro-max",
        "ì•„ì´í°16í”„ë¡œë§¥ìŠ¤": "iphone-16-pro-max",
        "ì—ì–´íŒŸ": "airpods",
        "ì—ì–´íŒŸ í”„ë¡œ": "airpods-pro",
        "ì—ì–´íŒŸí”„ë¡œ": "airpods-pro",
        "ì• í”Œ ë§¤ì§ í‚¤ë³´ë“œ": "apple-magic-keyboard",
        "ì• í”Œë§¤ì§í‚¤ë³´ë“œ": "apple-magic-keyboard",
        "ë§¤ì§ í‚¤ë³´ë“œ": "magic-keyboard",
        "ë§¤ì§í‚¤ë³´ë“œ": "magic-keyboard",
        "ë§¥ë¶": "macbook",
        "ì•„ì´íŒ¨ë“œ": "ipad",
        "ì• í”Œì›Œì¹˜": "apple-watch",
        # ê¸°íƒ€ ë¸Œëœë“œ
        "ì†Œë‹ˆ": "sony",
        "ì†Œë‹ˆ ë¬´ì„  í—¤ë“œí°": "sony-headphone",
        "ì†Œë‹ˆë¬´ì„ í—¤ë“œí°": "sony-headphone",
        "ë‹¤ì´ìŠ¨": "dyson",
    }

    # ì œí’ˆëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜
    safe_name = product_name.lower()

    # í•œê¸€ì„ ì˜ì–´ë¡œ ë³€í™˜
    for korean, english in korean_to_english.items():
        safe_name = safe_name.replace(korean, english)

    # ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ í•˜ì´í”ˆìœ¼ë¡œ ë³€í™˜
    import re

    safe_name = re.sub(r"[^\w\-]", "-", safe_name)
    safe_name = re.sub(r"-+", "-", safe_name)  # ì—°ì†ëœ í•˜ì´í”ˆ ì œê±°
    safe_name = safe_name.strip("-")  # ì•ë’¤ í•˜ì´í”ˆ ì œê±°

    # ë¹ˆ ë¬¸ìì—´ì´ë©´ ì›ë³¸ ë°˜í™˜
    if not safe_name:
        safe_name = product_name

    return safe_name


def split_content_into_sections(content: str) -> List[str]:
    """ë¦¬ë·° ë‚´ìš©ì„ ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆ„ê¸°"""
    sections = []
    current_section = ""
    lines = content.split("\n")

    for line in lines:
        if line.startswith("### ") and current_section.strip():
            # ìƒˆë¡œìš´ ì„¹ì…˜ì´ ì‹œì‘ë˜ë©´ ì´ì „ ì„¹ì…˜ ì €ì¥
            sections.append(current_section.strip())
            current_section = line + "\n"
        else:
            current_section += line + "\n"

    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
    if current_section.strip():
        sections.append(current_section.strip())

    return sections


def insert_external_images_between_sections(
    sections: List[str], images: List[Dict]
) -> str:
    """ì„¹ì…˜ ì‚¬ì´ì— ì™¸ë¶€ ì´ë¯¸ì§€ ë§í¬ ë°°ì¹˜"""
    if not images:
        return "\n".join(sections)

    result = []
    images_used = 0
    max_images = min(len(images), 3)  # ìµœëŒ€ 3ê°œ ì´ë¯¸ì§€ ì‚¬ìš©

    # ì²« ë²ˆì§¸ ì„¹ì…˜ì€ ì´ë¯¸ì§€ ì—†ì´ ì¶”ê°€
    if sections:
        result.append(sections[0])

    # ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ ì‚¬ì´ì— ì´ë¯¸ì§€ ë°°ì¹˜
    for i in range(1, len(sections)):
        # ì´ë¯¸ì§€ ì¶”ê°€ (ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ìˆ˜ ë‚´ì—ì„œ)
        if images_used < max_images and i <= max_images:
            img = images[images_used]
            image_caption = img.get("title", f"ì œí’ˆ ì´ë¯¸ì§€ {images_used + 1}")
            # ì™¸ë¶€ ë§í¬ì™€ ëŒ€ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
            image_md = f"\n![{image_caption}]({img['url']})\n"
            image_md += f"*{image_caption}*\n"
            # ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€ (í•´ìƒë„ ë“±)
            if img.get("width") and img.get("height"):
                image_md += f"*(ì´ë¯¸ì§€ í¬ê¸°: {img['width']}x{img['height']} í”½ì…€)*\n"
            result.append(image_md)
            images_used += 1

        # ë‹¤ìŒ ì„¹ì…˜ ì¶”ê°€
        result.append(sections[i])

    return "\n".join(result)


def save_post(state: BlogState) -> BlogState:
    """í¬ìŠ¤íŠ¸ ì €ì¥"""
    current_post = state.get("current_post", {})
    markdown = current_post.get("markdown", "")
    product_name = state.get("product_name", "")

    print(f"ğŸ’¾ í¬ìŠ¤íŠ¸ ì €ì¥ ì¤‘...")

    # íŒŒì¼ëª… ìƒì„±: review-<product-slug>-<shortid>.md
    product_slug = state.get("product_slug", slugify(product_name))
    shortid = str(uuid.uuid4())[:6]
    filename = f"review-{product_slug}-{shortid}.md"
    filepath = os.path.join(POSTS_DIR, filename)

    # ì‹¤ì œ íŒŒì¼ ì €ì¥
    try:
        os.makedirs(POSTS_DIR, exist_ok=True)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(markdown)
        print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        print(f"ğŸ“„ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n{markdown[:500]}...")

    state["current_post"]["filename"] = filename
    state["current_post"]["status"] = "saved"
    state["completed"] = True

    # ìƒì„±ëœ ë¦¬ë·° ê¸°ë¡ì— ì¶”ê°€
    add_review_record(product_name, filename)

    return state


def review_content(state: BlogState) -> BlogState:
    """ì»¨í…ì¸  ê²€í† """
    content = state.get("current_post", {}).get("content", "")
    search_results = state.get("search_results", {})

    print(f"ğŸ” ì»¨í…ì¸  ê²€í†  ì¤‘...")

    # ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì 
    revision_count = state.get("revision_count", 0)
    max_revisions = 2  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

    # ê²€í†  ê¸°ì¤€ (í™˜ê²½ì— ë”°ë¼ ì™„í™”)
    disable_llm = os.getenv("DISABLE_LLM") == "1"
    disable_search = os.getenv("DISABLE_WEB_SEARCH") == "1"

    min_length = 600 if disable_llm else 1200

    checks = {
        "length": len(content) >= min_length,
        "numbers": count_numeric_metrics(content) >= 3,
        "has_pros": "### ì¥ì " in content,
        "has_cons": "### ë‹¨ì " in content,
        "has_compare": "### ê²½ìŸ ì œí’ˆ ë¹„êµ" in content,
        "has_price": ("### ê°€ê²©" in content) or ("ê°€ê²© ë° êµ¬ë§¤ íŒ" in content),
        "has_faq": "### FAQ" in content,
    }

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ë„ ìµœëŒ€ ì¬ì‹œë„ í›„ì—ëŠ” í†µê³¼
    if (
        len(search_results.get("basic_info", [])) == 0
        and revision_count >= max_revisions
    ):
        checks["sources_used"] = True  # ê°•ì œë¡œ í†µê³¼
        print(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. ì¬ì‹œë„ ì œí•œ({max_revisions})ì— ë„ë‹¬í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        # ê²€ìƒ‰ ë¹„í™œì„±í™” ì‹œ ì¶œì²˜ ê°•ì œ í†µê³¼
        checks["sources_used"] = (
            True if disable_search else len(search_results.get("basic_info", [])) > 0
        )

    failed_checks = [k for k, v in checks.items() if not v]

    if failed_checks and revision_count < max_revisions:
        state["feedback"] = f"ê°œì„  í•„ìš”: {', '.join(failed_checks)}"
        state["current_post"]["needs_revision"] = True
        state["revision_count"] = revision_count + 1
    else:
        if revision_count >= max_revisions:
            state["feedback"] = (
                f"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜({max_revisions}) ë„ë‹¬ - í˜„ì¬ ìƒíƒœë¡œ ì§„í–‰"
            )
        else:
            state["feedback"] = "ê²€í†  í†µê³¼ - í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±"
        state["current_post"]["needs_revision"] = False

    print(f"ğŸ“Š ê²€í†  ê²°ê³¼: {state['feedback']}")
    if revision_count > 0:
        print(f"ğŸ“ˆ ì¬ì‹œë„ íšŸìˆ˜: {revision_count}/{max_revisions}")

    return state


# ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜
def should_revise(state: BlogState) -> str:
    """ìˆ˜ì • í•„ìš” ì—¬ë¶€ íŒë‹¨"""
    if state.get("current_post", {}).get("needs_revision", False):
        return "revise"
    return "continue"


def should_continue_after_analyze(state: BlogState) -> str:
    """ë¶„ì„ í›„ ê³„ì† ì§„í–‰ ì—¬ë¶€ íŒë‹¨"""
    current_post = state.get("current_post", {})
    if current_post.get("status") == "duplicate":
        return "end"
    return "research"


# ì›Œí¬í”Œë¡œìš° ìƒì„±
def create_workflow():
    """ì›¹ ê²€ìƒ‰ì´ í¬í•¨ëœ ì›Œí¬í”Œë¡œìš° ìƒì„±"""

    workflow = StateGraph(BlogState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze", analyze_task)
    workflow.add_node("research", research_product)  # ì›¹ ê²€ìƒ‰ ë…¸ë“œ ì¶”ê°€
    workflow.add_node("collect_images", collect_images)  # ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ ë…¸ë“œ ì¶”ê°€
    workflow.add_node("generate", generate_content)
    workflow.add_node("review", review_content)
    workflow.add_node("markdown", create_markdown)
    workflow.add_node("save", save_post)

    # ì—£ì§€ ì„¤ì •
    workflow.set_entry_point("analyze")

    # ë¶„ì„ í›„ ì¤‘ë³µ ì²´í¬ ì¡°ê±´ë¶€ ì—£ì§€
    workflow.add_conditional_edges(
        "analyze", should_continue_after_analyze, {"end": END, "research": "research"}
    )

    workflow.add_edge("research", "collect_images")  # ë¦¬ì„œì¹˜ í›„ ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘
    workflow.add_edge("collect_images", "generate")  # ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ í›„ ìƒì„±
    workflow.add_edge("generate", "review")

    # ì¡°ê±´ë¶€ ì—£ì§€
    workflow.add_conditional_edges(
        "review", should_revise, {"revise": "generate", "continue": "markdown"}
    )

    workflow.add_edge("markdown", "save")
    workflow.add_edge("save", END)

    # ì²´í¬í¬ì¸í„° ì„¤ì •
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    return app


# ---------------------------- í—¬í¼ í•¨ìˆ˜ë“¤ ----------------------------
def slugify(text: str) -> str:
    safe = text.lower().strip()
    safe = re.sub(r"[\s/]+", "-", safe)
    safe = re.sub(r"[^a-z0-9\-]+", "", safe)
    safe = re.sub(r"-+", "-", safe).strip("-")
    return safe or "post"


def build_unique_title(product_name: str) -> str:
    """ì œëª© íŒ¨í„´ì„ ë‹¤ì–‘í™”"""
    import random
    patterns = [
        f"{product_name} ë¦¬ë·°: ìƒì„¸ ë¶„ì„ê³¼ êµ¬ë§¤ ê°€ì´ë“œ",
        f"{product_name} ì™„ë²½ ê°€ì´ë“œ: íŠ¹ì§•, ì¥ë‹¨ì , ê°€ê²© ë¹„êµ",
        f"{product_name} ì´ì •ë¦¬: ì„±ëŠ¥ë¶€í„° ê°€ì„±ë¹„ê¹Œì§€",
        f"{product_name} ì‹¬ì¸µ ë¦¬ë·°: ì¥ì ê³¼ ë‹¨ì  ë¶„ì„",
        f"{product_name} êµ¬ë§¤ ì „ í•„ë…: ìŠ¤í™ê³¼ ì‹¤ì‚¬ìš© íŒ",
        f"{product_name} ë¶„ì„: íŠ¹ì§•Â·ê°€ê²©Â·ê²½ìŸ ì œí’ˆ ë¹„êµ",
        f"{product_name} ì™„ì „ ë¶„ì„: êµ¬ë§¤ ê°€ì´ë“œì™€ ì¶”ì²œ ëŒ€ìƒ",
    ]
    return random.choice(patterns)


def build_excerpt(product_name: str) -> str:
    """excerpt íŒ¨í„´ì„ ë‹¤ì–‘í™”"""
    import random
    patterns = [
        f"{product_name}ì˜ ì£¼ìš” íŠ¹ì§•, ì¥ë‹¨ì , ê°€ê²© ì •ë³´ì™€ êµ¬ë§¤ íŒ ì´ì •ë¦¬",
        f"{product_name} ìŠ¤í™ ë¶„ì„ê³¼ ê²½ìŸ ì œí’ˆ ë¹„êµ, ì¶”ì²œ ëŒ€ìƒ ì•ˆë‚´",
        f"{product_name}ì˜ ì„±ëŠ¥ê³¼ íŠ¹ì§•, ê°€ê²©ëŒ€ë³„ ì˜µì…˜ ìƒì„¸ ë¶„ì„",
        f"{product_name} ì™„ë²½ ê°€ì´ë“œ: íŠ¹ì§•ë¶€í„° êµ¬ë§¤ íŒê¹Œì§€",
        f"{product_name}ì˜ í•µì‹¬ ê¸°ëŠ¥ê³¼ ì¥ë‹¨ì , ê°€ê²© ë¹„êµ ì •ë³´",
        f"{product_name} ì¢…í•© ë¶„ì„: ìŠ¤í™, ê°€ê²©, ì‚¬ìš©ì í‰ê°€",
    ]
    return random.choice(patterns)


def count_numeric_metrics(text) -> int:
    if not isinstance(text, str):
        text = to_plain_text(text)
    return len(
        re.findall(
            r"\b\d+[\d,.]*(?:%|ë§Œì›|ì›|g|kg|mm|cm|mAh|ì‹œê°„|nit|Hz|GB|TB|inch|ì¸ì¹˜)?\b",
            text,
        )
    )


def passes_quality_gates(content: str) -> bool:
    checks = {
        "length": len(content) >= 1200,
        "numbers": count_numeric_metrics(content) >= 3,
        "has_pros": "### ì¥ì " in content,
        "has_cons": "### ë‹¨ì " in content,
        "has_compare": "### ê²½ìŸ ì œí’ˆ ë¹„êµ" in content,
        "has_price": ("### ê°€ê²©" in content) or ("ê°€ê²© ë° êµ¬ë§¤ íŒ" in content),
        "has_faq": "### FAQ" in content,
    }
    return all(checks.values())


def fetch_binary(url: str) -> bytes:
    try:
        req = Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urlopen(req, timeout=20) as resp:
            return resp.read()
    except (URLError, HTTPError) as e:
        print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return b""


def short_hash(text: str) -> str:
    return hashlib.sha256(text.encode("utf-8")).hexdigest()[:8]


def download_and_prepare_images(product_slug: str, images: List[dict]) -> List[dict]:
    os.makedirs(IMAGES_DIR, exist_ok=True)
    local_list: List[dict] = []
    for idx, img in enumerate(images[:3], start=1):
        url = img.get("url")
        if not url:
            continue
        try:
            filename_base = f"{product_slug}-{idx}-{short_hash(url)}"
            webp_path = os.path.join(IMAGES_DIR, f"{filename_base}.webp")
            if not os.path.exists(webp_path):
                data = fetch_binary(url)
                if not data:
                    continue
                image = Image.open(BytesIO(data))
                if image.mode not in ("RGB", "RGBA"):
                    image = image.convert("RGB")
                image.save(webp_path, "WEBP", quality=85, optimize=True)
            local_list.append(
                {
                    "path": f"/images/{os.path.basename(webp_path)}",
                    "alt": img.get("title") or f"{product_slug} ì´ë¯¸ì§€ {idx}",
                    "width": img.get("width", 0),
                    "height": img.get("height", 0),
                }
            )
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨({idx}): {e}")
            continue
    return local_list


def insert_local_images_between_sections(
    sections: List[str], local_images: List[dict]
) -> str:
    if not local_images:
        return "\n".join(sections)
    result: List[str] = []
    images_used = 0
    max_images = min(len(local_images), 3)
    if sections:
        result.append(sections[0])
    for i in range(1, len(sections)):
        if images_used < max_images and i <= max_images:
            img = local_images[images_used]
            image_md = f"\n![{img['alt']}]({img['path']})\n"
            result.append(image_md)
            images_used += 1
        result.append(sections[i])
    return "\n".join(result)


def estimate_rating_from_content(content: str) -> float:
    pros = len(re.findall(r"^[-*]\s", content, flags=re.MULTILINE))
    cons = content.lower().count("ë‹¨ì ")
    base = 4.2
    adj = min(0.5, max(-0.5, (pros - cons) * 0.05))
    return round(base + adj, 1)


def generate_template_content(product_name: str) -> str:
    today = datetime.now().strftime("%Y-%m-%d")
    return f"""
### ì œí’ˆ ì†Œê°œ
{product_name}ëŠ” ìµœê·¼ ì‚¬ìš©ìë“¤ì´ ë§ì´ ì°¾ëŠ” ì œí’ˆì…ë‹ˆë‹¤. ë³¸ ë¦¬ë·°ì—ì„œëŠ” ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•µì‹¬ ê¸°ëŠ¥ê³¼ ì²´ê° í¬ì¸íŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. (ì‘ì„±ì¼: {today})

### ì£¼ìš” íŠ¹ì§•
- ì„±ëŠ¥: ìµœì‹  ì¹©ì…‹/ëª¨ë“ˆì„ ì ìš©í•´ ì¼ìƒ ì‘ì—…ê³¼ ë©€í‹°íƒœìŠ¤í‚¹ì— ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- ë””ìŠ¤í”Œë ˆì´: 120Hz ì£¼ì‚¬ìœ¨, ìµœëŒ€ 1600nit ë°ê¸°, ì •í™•í•œ ìƒ‰ ì¬í˜„.
- ë°°í„°ë¦¬: 4,400mAh ìˆ˜ì¤€ì˜ ë°°í„°ë¦¬ë¡œ ì¼ë°˜ ì‚¬ìš© ê¸°ì¤€ 1ì¼ ì‚¬ìš© ê°€ëŠ¥.
- ë¬´ê²Œ/í¬ê¸°: ì•½ 190g, ë‘ê»˜ 7.8mmë¡œ íœ´ëŒ€ì„± ìš°ìˆ˜.

### ì¥ì 
- ë””ìŠ¤í”Œë ˆì´ í’ˆì§ˆì´ ìš°ìˆ˜í•´ ì•¼ì™¸(ìµœëŒ€ 1600nit)ì—ì„œë„ ê°€ë…ì„±ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.
- ë°œì—´/ì†ŒìŒ ì–µì œê°€ ì–‘í˜¸í•˜ê³ , ì•± ì „í™˜ ì†ë„ê°€ ë¹ ë¦…ë‹ˆë‹¤.
- ìƒíƒœê³„/ì•¡ì„¸ì„œë¦¬ ì—°ë™ì„±ì´ ì¢‹ì•„ ìƒì‚°ì„± í™œìš©ì´ ìœ ë¦¬í•©ë‹ˆë‹¤.

### ë‹¨ì 
- ì¶œê³ ê°€ê°€ ë†’ì•„ ê°€ì„±ë¹„ ê´€ì ì—ì„  ë¶€ë‹´ì´ ìˆìŠµë‹ˆë‹¤.
- ê¸°ë³¸ ì €ì¥ìš©ëŸ‰(128GB/256GB)ì€ ëŒ€ìš©ëŸ‰ ì´¬ì˜Â·ì•± ë‹¤ì¤‘ ì„¤ì¹˜ ì‹œ ì—¬ìœ ê°€ ì ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê²½ìŸ ì œí’ˆ ë¹„êµ
- ëŒ€ì•ˆ A: ìœ ì‚¬ ì„±ëŠ¥ ëŒ€ë¹„ ê°€ê²© ë©”ë¦¬íŠ¸ê°€ í¬ê³ , ë¬´ê²Œê°€ ë” ê°€ë³ìŠµë‹ˆë‹¤.
- ëŒ€ì•ˆ B: ì¹´ë©”ë¼/ì˜¤ë””ì˜¤ íŠ¹í™”ë¡œ ì½˜í…ì¸  ì œì‘ìì—ê²Œ ìœ ë¦¬í•©ë‹ˆë‹¤.

### ê°€ê²© ë° êµ¬ë§¤ íŒ
- ì˜¨ë¼ì¸ ìµœì €ê°€ ê¸°ì¤€ 100ë§Œì›~150ë§Œì›ëŒ€ í˜•ì„±. ì¹´ë“œ/í¬ì¸íŠ¸/ë²ˆë“¤ í• ì¸ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
- ë¦¬í¼/ê³µì‹ êµìœ¡ í• ì¸/ë³´ìƒ íŒë§¤ ë“± ì±„ë„ë³„ í˜œíƒì„ ë¹„êµí•˜ì„¸ìš”.

### FAQ
- Q. ë°°í„°ë¦¬ ì‹œê°„ì€ ì–´ëŠ ì •ë„ì¸ê°€ìš”?
  A. ì¼ë°˜ ì‚¬ìš© ê¸°ì¤€ í•˜ë£¨(ìŠ¤í¬ë¦° ì˜¨ 5~7ì‹œê°„) ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- Q. ë°©ìˆ˜ ë°©ì§„ ë“±ê¸‰ì€?
  A. ì¼ìƒ ìƒí™œ ë°©ìˆ˜(ì˜ˆ: IP68 ìˆ˜ì¤€)ë¡œ ë¹„/ë•€ì— ëŒ€ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- Q. ëˆ„êµ¬ì—ê²Œ ì¶”ì²œí•˜ë‚˜ìš”?
  A. ê³ ì£¼ì‚¬ìœ¨ í™”ë©´Â·ì¹´ë©”ë¼Â·ìƒíƒœê³„ ì—°ë™ì„ ì¤‘ì‹œí•˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì í•©í•©ë‹ˆë‹¤.

### ì´í‰ ë° ì¶”ì²œ ëŒ€ìƒ
{product_name}ëŠ” ë””ìŠ¤í”Œë ˆì´Â·ì„±ëŠ¥Â·ì—°ë™ ì¸¡ë©´ì—ì„œ ì™„ì„±ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ê°€ê²©ì€ ë¶€ë‹´ìŠ¤ëŸ½ì§€ë§Œ, ìµœì‹  ê¸°ëŠ¥ê³¼ ìƒíƒœê³„ í¸ì˜ê°€ í•„ìš”í•œ ì‚¬ìš©ìì—ê²Œ ì¶©ë¶„íˆ ì¶”ì²œí•  ë§Œí•©ë‹ˆë‹¤.
"""


def to_plain_text(value) -> str:
    if isinstance(value, str):
        return value
    if isinstance(value, list):
        try:
            return " ".join(to_plain_text(v) for v in value)
        except Exception:
            return " ".join(str(v) for v in value)
    if isinstance(value, dict):
        for key in ("text", "content", "message", "data"):
            if key in value:
                return to_plain_text(value[key])
        try:
            return " ".join(to_plain_text(v) for v in value.values())
        except Exception:
            return str(value)
    return str(value)


# ë©”ì¸ ì‹¤í–‰
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë¦¬ë·° ë¸”ë¡œê·¸ ìë™í™” ì‹œìŠ¤í…œ (ì›¹ ê²€ìƒ‰ ë²„ì „)")
    print("=" * 60)

    # ì›Œí¬í”Œë¡œìš° ìƒì„±
    app = create_workflow()

    # ê¸°ì¡´ ë¦¬ë·° ëª©ë¡ í‘œì‹œ
    existing_reviews = load_generated_reviews()
    if existing_reviews:
        print(f"\nğŸ“š ê¸°ì¡´ ìƒì„±ëœ ë¦¬ë·° ëª©ë¡ ({len(existing_reviews)}ê°œ):")
        for i, review in enumerate(existing_reviews[-5:], 1):  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
            print(f"  {i}. {review['product_name']} ({review['created_at'][:10]})")
        if len(existing_reviews) > 5:
            print(f"  ... ì™¸ {len(existing_reviews) - 5}ê°œ ë”")
        print()

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("ì œí’ˆ ë¦¬ë·°ë¥¼ ì‘ì„±í•  ì œí’ˆì„ ì…ë ¥í•˜ì„¸ìš”.")
    print("ì˜ˆì‹œ: ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼, ì—ì–´íŒŸ í”„ë¡œ 2, ë‹¤ì´ìŠ¨ V15")
    print("ìŠ¤íƒ€ì¼ì„ ì˜ˆì‹œ ë¦¬ë·°ì— ë§ì¶”ê³  ì‹¶ë‹¤ë©´ '@review-mx-master-4-ddc17c.md (1-276)' ì²˜ëŸ¼ ëì— ë¶™ì—¬ë„ ë©ë‹ˆë‹¤.")
    product_input = input("\nì œí’ˆëª…: ").strip()

    if not product_input:
        product_input = "ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼"
        print(f"ê¸°ë³¸ê°’ ì‚¬ìš©: {product_input}")

    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "task": f"{product_input} ë¦¬ë·° ì‘ì„±",
        "product_name": "",
        "search_results": {},
        "posts": [],
        "current_post": {},
        "feedback": "",
        "completed": False,
        "images": [],
    }

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    config = {"configurable": {"thread_id": f"review_{datetime.now().timestamp()}"}}

    print(f"\nğŸ“Œ ì‘ì—…: {initial_state['task']}")
    print("=" * 60)

    # ì‹¤í–‰
    for output in app.stream(initial_state, config):
        for key, value in output.items():
            print(f"âœ… {key} ë…¸ë“œ ì™„ë£Œ")

    print("=" * 60)
    print("âœ¨ ë¦¬ë·° ì‘ì„± ì™„ë£Œ!")


if __name__ == "__main__":
    main()
