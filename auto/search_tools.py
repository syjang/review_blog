"""
ì›¹ ê²€ìƒ‰ ë„êµ¬ ëª¨ìŒ
ì œí’ˆ ë¦¬ë·°ë¥¼ ìœ„í•œ ìµœì‹  ì •ë³´ ê²€ìƒ‰ ë° ì´ë¯¸ì§€ ê²€ìƒ‰
"""

from ddgs import DDGS
from typing import List, Dict
import time
from random import uniform
import os
import requests
import urllib.parse
from PIL import Image
from io import BytesIO



class WebSearcher:
    """ì›¹ ê²€ìƒ‰ ë„êµ¬"""

    def __init__(self):
        # User-Agent í—¤ë”ì™€ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        self.delay_range = (2.0, 4.0)  # ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ ë²”ìœ„ (ì¦ê°€)
        self.max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        self.image_save_dir = "../app/public/images"  # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬

    def _search_with_retry(self, search_func, *args, **kwargs):
        """
        ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ê²€ìƒ‰ ì‹¤í–‰
        """
        for attempt in range(self.max_retries):
            try:
                # ì²« ë²ˆì§¸ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì§€ì—° ì‹œê°„ ì¶”ê°€
                if attempt > 0:
                    delay = uniform(*self.delay_range) * (attempt + 1)  # ì¬ì‹œë„ë§ˆë‹¤ ì§€ì—° ì¦ê°€
                    print(f"â³ {delay:.1f}ì´ˆ ëŒ€ê¸° ì¤‘... (ì¬ì‹œë„ {attempt + 1}/{self.max_retries})")
                    time.sleep(delay)
                else:
                    # ì²« ì‹œë„ì—ë„ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€
                    time.sleep(uniform(0.5, 1.0))

                # ë§¤ë²ˆ ìƒˆë¡œìš´ DDGS ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„¸ì…˜ ì´ˆê¸°í™”)
                with DDGS(timeout=30) as ddgs:
                    results = search_func(ddgs, *args, **kwargs)

                # ì„±ê³µí•˜ë©´ ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´ ì§€ì—°
                time.sleep(uniform(1.0, 2.0))

                return results

            except Exception as e:
                error_msg = str(e)
                # Rate limit ê´€ë ¨ ì—ëŸ¬ ì²´í¬
                if any(x in error_msg.lower() for x in ['ratelimit', 'rate limit', '429', '202']):
                    if attempt < self.max_retries - 1:
                        print(f"âš ï¸ Rate limit ê°ì§€. ì¬ì‹œë„ ì¤€ë¹„ì¤‘...")
                        continue
                    else:
                        print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {e}")
                        return []  # raise ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
                # "Exception occurred in previous call" ì²˜ë¦¬
                elif 'exception occurred in previous call' in error_msg.lower():
                    print(f"âš ï¸ ì´ì „ í˜¸ì¶œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê±´ë„ˆë›°ê¸°")
                    return []
                else:
                    print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    return []  # raise ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

        return []

    def search_product_info(self, product_name: str, max_results: int = 5) -> List[Dict]:
        """
        ì œí’ˆ ì •ë³´ ê²€ìƒ‰

        Args:
            product_name: ê²€ìƒ‰í•  ì œí’ˆëª…
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” '{product_name}' ê²€ìƒ‰ ì¤‘...")

        try:
            # ì œí’ˆ ë¦¬ë·° ë° ì‚¬ì–‘ ê²€ìƒ‰
            search_query = f"{product_name} ë¦¬ë·° ì‚¬ì–‘ íŠ¹ì§•"

            # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ê²€ìƒ‰
            results = self._search_with_retry(
                lambda ddgs: list(ddgs.text(
                    search_query,
                    max_results=max_results,
                    region='kr-kr',  # í•œêµ­ ì§€ì—­ ê²€ìƒ‰
                    safesearch='moderate'
                ))
            )

            formatted_results = []
            for result in results:
                formatted_results.append({
                    "title": result.get("title", ""),
                    "body": result.get("body", ""),
                    "url": result.get("href", "")
                })

            return formatted_results

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def search_product_price(self, product_name: str) -> List[Dict]:
        """
        ì œí’ˆ ê°€ê²© ì •ë³´ ê²€ìƒ‰

        Args:
            product_name: ê²€ìƒ‰í•  ì œí’ˆëª…

        Returns:
            ê°€ê²© ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ’° '{product_name}' ê°€ê²© ê²€ìƒ‰ ì¤‘...")

        try:
            # ê°€ê²© ì •ë³´ ê²€ìƒ‰
            search_query = f"{product_name} ê°€ê²© ìµœì €ê°€"

            # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ê²€ìƒ‰
            results = self._search_with_retry(
                lambda ddgs: list(ddgs.text(
                    search_query,
                    max_results=3,
                    region='kr-kr'
                ))
            )

            price_info = []
            for result in results:
                price_info.append({
                    "source": result.get("title", ""),
                    "description": result.get("body", ""),
                    "url": result.get("href", "")
                })

            return price_info

        except Exception as e:
            print(f"âŒ ê°€ê²© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def search_recent_news(self, product_name: str) -> List[Dict]:
        """
        ì œí’ˆ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰

        Args:
            product_name: ê²€ìƒ‰í•  ì œí’ˆëª…

        Returns:
            ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ“° '{product_name}' ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")

        try:
            # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë‰´ìŠ¤ ê²€ìƒ‰
            results = self._search_with_retry(
                lambda ddgs: list(ddgs.news(
                    f"{product_name}",
                    max_results=3,
                    region='kr-kr'
                ))
            )

            news = []
            for result in results:
                news.append({
                    "title": result.get("title", ""),
                    "body": result.get("body", ""),
                    "date": result.get("date", ""),
                    "source": result.get("source", ""),
                    "url": result.get("url", "")
                })

            return news

        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def search_user_reviews(self, product_name: str) -> List[Dict]:
        """
        ì‚¬ìš©ì ë¦¬ë·° ê²€ìƒ‰

        Args:
            product_name: ê²€ìƒ‰í•  ì œí’ˆëª…

        Returns:
            ë¦¬ë·° ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        print(f"â­ '{product_name}' ì‚¬ìš©ì ë¦¬ë·° ê²€ìƒ‰ ì¤‘...")

        try:
            # ì‚¬ìš©ì ë¦¬ë·° ê²€ìƒ‰
            search_query = f"{product_name} ì‚¬ìš©í›„ê¸° ì¥ë‹¨ì  ì‹¤ì‚¬ìš©"

            # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ê²€ìƒ‰
            results = self._search_with_retry(
                lambda ddgs: list(ddgs.text(
                    search_query,
                    max_results=5,
                    region='kr-kr'
                ))
            )

            reviews = []
            for result in results:
                reviews.append({
                    "title": result.get("title", ""),
                    "summary": result.get("body", ""),
                    "url": result.get("href", "")
                })

            return reviews

        except Exception as e:
            print(f"âŒ ë¦¬ë·° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def search_product_images(self, product_name: str, max_results: int = 5) -> List[Dict]:
        """
        ì œí’ˆ ì´ë¯¸ì§€ ê²€ìƒ‰

        Args:
            product_name: ê²€ìƒ‰í•  ì œí’ˆëª…
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ–¼ï¸ '{product_name}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

        try:
            # ì œí’ˆ ì´ë¯¸ì§€ ê²€ìƒ‰
            search_query = f"{product_name} ì œí’ˆ ì‚¬ì§„"

            # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì´ë¯¸ì§€ ê²€ìƒ‰
            results = self._search_with_retry(
                lambda ddgs: list(ddgs.images(
                    search_query,
                    max_results=max_results,
                    region='kr-kr'
                ))
            )

            images = []
            for result in results:
                # ì‹¤ì œ ì´ë¯¸ì§€ URL ì°¾ê¸° (image > thumbnail > url ìˆœì„œë¡œ ìš°ì„ ìˆœìœ„)
                image_url = result.get("image") or result.get("thumbnail") or result.get("url", "")

                images.append({
                    "title": result.get("title", ""),
                    "url": image_url,  # ì‹¤ì œ ì´ë¯¸ì§€ URL
                    "thumbnail": result.get("thumbnail", ""),
                    "source": result.get("source", ""),
                    "width": result.get("width", 0),
                    "height": result.get("height", 0)
                })

            return images

        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def get_image_extension(self, image_url: str, response) -> str:
        """
        ì´ë¯¸ì§€ URLê³¼ ì‘ë‹µì—ì„œ ì‹¤ì œ í™•ì¥ì ì¶”ì¶œ
        ëª¨ë“  ì´ë¯¸ì§€ë¥¼ WebPë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥

        Args:
            image_url: ì´ë¯¸ì§€ URL
            response: HTTP ì‘ë‹µ ê°ì²´

        Returns:
            ì´ë¯¸ì§€ í™•ì¥ì (í•­ìƒ 'webp')
        """
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ WebP í˜•ì‹ìœ¼ë¡œ ì €ì¥
        return 'webp'

    def is_valid_image_response(self, response) -> bool:
        """
        ì‘ë‹µì´ ì‹¤ì œ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸

        Args:
            response: HTTP ì‘ë‹µ ê°ì²´

        Returns:
            ì´ë¯¸ì§€ì¸ì§€ ì—¬ë¶€
        """
        # Content-Type í™•ì¸
        content_type = response.headers.get('content-type', '').lower()
        if not any(img_type in content_type for img_type in ['image/jpeg', 'image/png', 'image/gif', 'image/webp']):
            return False

        # Content-Length í™•ì¸ (ë„ˆë¬´ ì‘ìœ¼ë©´ ì˜ì‹¬)
        content_length = response.headers.get('content-length')
        if content_length and int(content_length) < 1000:  # 1KB ë¯¸ë§Œì´ë©´ ì˜ì‹¬
            return False

        return True

    def download_image(self, image_url: str, base_filename: str) -> tuple[bool, str]:
        """
        ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° WebPë¡œ ë³€í™˜

        Args:
            image_url: ì´ë¯¸ì§€ URL
            base_filename: ê¸°ë³¸ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)

        Returns:
            (ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€, ì‹¤ì œ íŒŒì¼ëª…)
        """
        try:
            # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(self.image_save_dir, exist_ok=True)

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }

            # GET ìš”ì²­ìœ¼ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = requests.get(image_url, headers=headers, timeout=30)
            response.raise_for_status()

            # ì‹¤ì œ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
            if not self.is_valid_image_response(response):
                print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ ì‘ë‹µ: {image_url}")
                return False, base_filename + ".webp"

            # ì´ë¯¸ì§€ë¥¼ PILë¡œ ì—´ê³  WebPë¡œ ë³€í™˜
            try:
                # ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì´ë¯¸ì§€ ì—´ê¸°
                image = Image.open(BytesIO(response.content))

                # RGBA ëª¨ë“œê°€ ì•„ë‹ˆë©´ RGBë¡œ ë³€í™˜ (WebP í˜¸í™˜ì„±ì„ ìœ„í•´)
                if image.mode in ('RGBA', 'LA'):
                    # íˆ¬ëª…ë„ê°€ ìˆëŠ” ì´ë¯¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                    pass
                elif image.mode != 'RGB':
                    image = image.convert('RGB')

                # WebP íŒŒì¼ëª… ìƒì„±
                actual_filename = f"{base_filename}.webp"
                filepath = os.path.join(self.image_save_dir, actual_filename)

                # WebP í˜•ì‹ìœ¼ë¡œ ì €ì¥ (í’ˆì§ˆ 85ë¡œ ì„¤ì •í•˜ì—¬ í¬ê¸°ì™€ í’ˆì§ˆ ê· í˜•)
                image.save(filepath, 'WEBP', quality=85, optimize=True)

                print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ (WebP): {filepath}")
                return True, actual_filename

            except Exception as img_error:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ìœ¼ë¡œ ì €ì¥ ì‹œë„: {img_error}")

                # PIL ë³€í™˜ ì‹¤íŒ¨ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
                actual_filename = f"{base_filename}.webp"
                filepath = os.path.join(self.image_save_dir, actual_filename)

                with open(filepath, 'wb') as f:
                    f.write(response.content)

                print(f"âœ… ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filepath}")
                return True, actual_filename

        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False, base_filename + ".webp"

    def get_comprehensive_info(self, product_name: str) -> Dict:
        """
        ì œí’ˆì— ëŒ€í•œ ì¢…í•© ì •ë³´ ìˆ˜ì§‘

        Args:
            product_name: ê²€ìƒ‰í•  ì œí’ˆëª…

        Returns:
            ì¢…í•© ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        print(f"ğŸ¯ '{product_name}' ì¢…í•© ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
        print("="*60)
        print("âš ï¸ Rate limit ë°©ì§€ë¥¼ ìœ„í•´ ê²€ìƒ‰ ê°„ ì§€ì—° ì‹œê°„ì´ ì ìš©ë©ë‹ˆë‹¤...")

        comprehensive_info = {
            "product": product_name,
            "basic_info": self.search_product_info(product_name),
            "price_info": self.search_product_price(product_name),
            "recent_news": self.search_recent_news(product_name),
            "user_reviews": self.search_user_reviews(product_name),
            "images": self.search_product_images(product_name)
        }

        print("="*60)
        print(f"âœ… ì¢…í•© ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!")

        return comprehensive_info

    def download_product_images(self, product_name: str, images: List[Dict], max_downloads: int = 3) -> List[str]:
        """
        ì œí’ˆ ì´ë¯¸ì§€ë“¤ì„ ë‹¤ìš´ë¡œë“œ

        Args:
            product_name: ì œí’ˆëª…
            images: ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            max_downloads: ìµœëŒ€ ë‹¤ìš´ë¡œë“œ ìˆ˜

        Returns:
            ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ“¥ '{product_name}' ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")

        downloaded_files = []
        # í•œê¸€ ì œí’ˆëª…ì„ ì˜ì–´ë¡œ ë³€í™˜
        safe_product_name = self.translate_korean_product_name(product_name)

        for i, image in enumerate(images[:max_downloads]):
            if not image.get("url"):
                continue

            # íŒŒì¼ëª… ìƒì„± (í™•ì¥ì ì œì™¸)
            base_filename = f"{safe_product_name}-{i+1}"

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì‹¤ì œ í™•ì¥ì í¬í•¨)
            success, actual_filename = self.download_image(image["url"], base_filename)
            if success:
                local_path = f"/images/{actual_filename}"
                downloaded_files.append({
                    "filename": actual_filename,
                    "local_path": local_path,
                    "original_url": image["url"],
                    "title": image.get("title", "")
                })

        print(f"âœ… ì´ {len(downloaded_files)}ê°œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        return downloaded_files

    def translate_korean_product_name(self, product_name: str) -> str:
        """
        í•œê¸€ ì œí’ˆëª…ì„ ì˜ì–´ë¡œ ë³€í™˜

        Args:
            product_name: í•œê¸€ ì œí’ˆëª…

        Returns:
            ì˜ì–´ ì œí’ˆëª…
        """
        # í•œê¸€ ì œí’ˆëª…ì„ ì˜ì–´ë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        korean_to_english = {
            # ì‚¼ì„± ì œí’ˆ
            "ê°¤ëŸ­ì‹œ": "galaxy",
            "ê°¤ëŸ­ì‹œs": "galaxy-s",
            "ê°¤ëŸ­ì‹œs24": "galaxy-s24",
            "ê°¤ëŸ­ì‹œs25": "galaxy-s25",
            "ê°¤ëŸ­í´ë“œ": "galaxy-fold",
            "ê°¤ëŸ­í´ë“œ7": "galaxy-fold7",
            "ë²„ì¦ˆí”„ë¡œ": "buds-pro",
            "ë²„ì¦ˆí”„ë¡œ3": "buds-pro3",

            # ì• í”Œ ì œí’ˆ
            "ì•„ì´í°": "iphone",
            "ì•„ì´í°16": "iphone-16",
            "ì•„ì´í°16í”„ë¡œ": "iphone-16-pro",
            "ì•„ì´í°16í”„ë¡œë§¥ìŠ¤": "iphone-16-pro-max",
            "ì—ì–´íŒŸ": "airpods",
            "ì—ì–´íŒŸí”„ë¡œ": "airpods-pro",
            "ì• í”Œë§¤ì§í‚¤ë³´ë“œ": "apple-magic-keyboard",
            "ë§¤ì§í‚¤ë³´ë“œ": "magic-keyboard",
            "ë§¥ë¶": "macbook",
            "ì•„ì´íŒ¨ë“œ": "ipad",
            "ì• í”Œì›Œì¹˜": "apple-watch",

            # ê¸°íƒ€ ë¸Œëœë“œ
            "ì†Œë‹ˆ": "sony",
            "ì†Œë‹ˆë¬´ì„ í—¤ë“œí°": "sony-headphone",
            "ë‹¤ì´ìŠ¨": "dyson",
            "lg": "lg",
            "ì‚¼ì„±": "samsung",

            # ì¼ë°˜ ë‹¨ì–´
            "ë¦¬ë·°": "review",
            "ìš¸íŠ¸ë¼": "ultra",
            "í”„ë¡œ": "pro",
            "ë§¥ìŠ¤": "max",
            "ë¯¸ë‹ˆ": "mini",
            "í”ŒëŸ¬ìŠ¤": "+",
            "ë¬´ì„ ": "wireless",
            "í—¤ë“œí°": "headphone",
            "í‚¤ë³´ë“œ": "keyboard",
            "ë§ˆìš°ìŠ¤": "mouse",
        }

        # ì œí’ˆëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ê³µë°± ì œê±°
        safe_name = product_name.lower().replace(" ", "").replace("-", "")

        # í•œê¸€ì„ ì˜ì–´ë¡œ ë³€í™˜
        for korean, english in korean_to_english.items():
            safe_name = safe_name.replace(korean, english)

        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° í•˜ì´í”ˆìœ¼ë¡œ ë³€í™˜
        import re
        safe_name = re.sub(r'[^a-zA-Z0-9\-]', '-', safe_name)
        safe_name = re.sub(r'-+', '-', safe_name)  # ì—°ì†ëœ í•˜ì´í”ˆ ì œê±°
        safe_name = safe_name.strip('-')  # ì•ë’¤ í•˜ì´í”ˆ ì œê±°

        # ë¹ˆ ë¬¸ìì—´ì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not safe_name:
            safe_name = "product"

        return safe_name


def format_search_results(search_data: Dict) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        search_data: ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°

    Returns:
        í¬ë§·íŒ…ëœ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´
    """
    markdown = f"# {search_data['product']} ê²€ìƒ‰ ê²°ê³¼\n\n"

    # ê¸°ë³¸ ì •ë³´
    if search_data.get("basic_info"):
        markdown += "## ğŸ“‹ ì œí’ˆ ì •ë³´\n\n"
        for info in search_data["basic_info"][:3]:
            markdown += f"### {info['title']}\n"
            markdown += f"{info['body']}\n"
            markdown += f"[ìì„¸íˆ ë³´ê¸°]({info['url']})\n\n"

    # ê°€ê²© ì •ë³´
    if search_data.get("price_info"):
        markdown += "## ğŸ’° ê°€ê²© ì •ë³´\n\n"
        for price in search_data["price_info"]:
            markdown += f"- **{price['source']}**: {price['description']}\n"

    # ìµœì‹  ë‰´ìŠ¤
    if search_data.get("recent_news"):
        markdown += "\n## ğŸ“° ìµœì‹  ë‰´ìŠ¤\n\n"
        for news in search_data["recent_news"]:
            markdown += f"- **{news['title']}** ({news.get('date', 'N/A')})\n"
            markdown += f"  {news['body'][:100]}...\n"

    # ì‚¬ìš©ì ë¦¬ë·°
    if search_data.get("user_reviews"):
        markdown += "\n## â­ ì‚¬ìš©ì ë¦¬ë·°\n\n"
        for review in search_data["user_reviews"][:3]:
            markdown += f"- {review['title']}\n"
            markdown += f"  {review['summary'][:100]}...\n"

    return markdown


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    searcher = WebSearcher()

    # í…ŒìŠ¤íŠ¸í•  ì œí’ˆ
    test_product = "ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼"

    print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì œí’ˆ: {test_product}")
    print("-"*60)

    # ì¢…í•© ì •ë³´ ìˆ˜ì§‘
    info = searcher.get_comprehensive_info(test_product)

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š ìˆ˜ì§‘ëœ ì •ë³´:")
    print(f"- ê¸°ë³¸ ì •ë³´: {len(info['basic_info'])}ê°œ")
    print(f"- ê°€ê²© ì •ë³´: {len(info['price_info'])}ê°œ")
    print(f"- ìµœì‹  ë‰´ìŠ¤: {len(info['recent_news'])}ê°œ")
    print(f"- ì‚¬ìš©ì ë¦¬ë·°: {len(info['user_reviews'])}ê°œ")

    # ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ…
    markdown_result = format_search_results(info)

    print("\nğŸ“ ë§ˆí¬ë‹¤ìš´ ê²°ê³¼ (ì²« 500ì):")
    print(markdown_result[:500])