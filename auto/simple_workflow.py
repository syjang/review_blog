"""
ê°„ë‹¨í•œ LangGraph ì˜ˆì œ - Function calling ì—†ì´!
ì´ ì˜ˆì œëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ LangGraph ì‚¬ìš©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

from typing import TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from config import get_llm
import os
from dotenv import load_dotenv

load_dotenv()


class BlogState(TypedDict):
    """ë¸”ë¡œê·¸ ë¦¬ë·° ìƒíƒœ"""
    product: str
    intro: str
    pros: str
    cons: str
    conclusion: str
    final_review: str


def create_simple_workflow():
    """
    Function calling ì—†ì´ ì‘ë™í•˜ëŠ” ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš°
    ê° ë…¸ë“œëŠ” ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    # ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš© (gpt-3.5-turbo ë˜ëŠ” ë¬´ë£Œ ëª¨ë¸)
    llm = get_llm("gpt-3.5-turbo", temperature=0.7)

    def write_intro(state: BlogState) -> BlogState:
        """ì„œë¡  ì‘ì„±"""
        print("ğŸ“ ì„œë¡  ì‘ì„± ì¤‘...")

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ë¦¬ë·° ì‘ì„±ìì…ë‹ˆë‹¤."),
            HumanMessage(content=f"{state['product']}ì— ëŒ€í•œ ë¦¬ë·° ì„œë¡ ì„ 2ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”.")
        ]

        response = llm.invoke(messages)
        state['intro'] = response.content if hasattr(response, 'content') else str(response)
        return state

    def write_pros(state: BlogState) -> BlogState:
        """ì¥ì  ì‘ì„±"""
        print("âœ… ì¥ì  ì‘ì„± ì¤‘...")

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ë¦¬ë·° ì‘ì„±ìì…ë‹ˆë‹¤."),
            HumanMessage(content=f"{state['product']}ì˜ ì¥ì  3ê°€ì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.")
        ]

        response = llm.invoke(messages)
        state['pros'] = response.content if hasattr(response, 'content') else str(response)
        return state

    def write_cons(state: BlogState) -> BlogState:
        """ë‹¨ì  ì‘ì„±"""
        print("âŒ ë‹¨ì  ì‘ì„± ì¤‘...")

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ë¦¬ë·° ì‘ì„±ìì…ë‹ˆë‹¤."),
            HumanMessage(content=f"{state['product']}ì˜ ë‹¨ì  2ê°€ì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.")
        ]

        response = llm.invoke(messages)
        state['cons'] = response.content if hasattr(response, 'content') else str(response)
        return state

    def write_conclusion(state: BlogState) -> BlogState:
        """ê²°ë¡  ì‘ì„±"""
        print("ğŸ¯ ê²°ë¡  ì‘ì„± ì¤‘...")

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ë¦¬ë·° ì‘ì„±ìì…ë‹ˆë‹¤."),
            HumanMessage(content=f"{state['product']}ì— ëŒ€í•œ ìµœì¢… í‰ê°€ë¥¼ 2ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”.")
        ]

        response = llm.invoke(messages)
        state['conclusion'] = response.content if hasattr(response, 'content') else str(response)
        return state

    def combine_review(state: BlogState) -> BlogState:
        """ì „ì²´ ë¦¬ë·° ì¡°í•©"""
        print("ğŸ“„ ìµœì¢… ë¦¬ë·° ìƒì„± ì¤‘...")

        final_review = f"""
# {state['product']} ë¦¬ë·°

## ì„œë¡ 
{state['intro']}

## ì¥ì 
{state['pros']}

## ë‹¨ì 
{state['cons']}

## ê²°ë¡ 
{state['conclusion']}
"""
        state['final_review'] = final_review
        return state

    # ì›Œí¬í”Œë¡œìš° ìƒì„±
    workflow = StateGraph(BlogState)

    # ë…¸ë“œ ì¶”ê°€ (ê° ë…¸ë“œëŠ” ë…ë¦½ì ì¸ ì‘ì—…)
    workflow.add_node("intro", write_intro)
    workflow.add_node("pros", write_pros)
    workflow.add_node("cons", write_cons)
    workflow.add_node("conclusion", write_conclusion)
    workflow.add_node("combine", combine_review)

    # ìˆœì°¨ì  ì‹¤í–‰ ì„¤ì •
    workflow.set_entry_point("intro")
    workflow.add_edge("intro", "pros")
    workflow.add_edge("pros", "cons")
    workflow.add_edge("cons", "conclusion")
    workflow.add_edge("conclusion", "combine")
    workflow.add_edge("combine", END)

    return workflow.compile()


def run_simple_review(product_name: str):
    """ê°„ë‹¨í•œ ë¦¬ë·° ì‹¤í–‰"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ ê°„ë‹¨í•œ ë¦¬ë·° ìƒì„±: {product_name}")
    print(f"{'='*60}\n")

    # ì›Œí¬í”Œë¡œìš° ìƒì„±
    app = create_simple_workflow()

    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "product": product_name,
        "intro": "",
        "pros": "",
        "cons": "",
        "conclusion": "",
        "final_review": ""
    }

    # ì‹¤í–‰
    try:
        result = app.invoke(initial_state)
        print("\n" + "="*60)
        print("âœ¨ ë¦¬ë·° ìƒì„± ì™„ë£Œ!")
        print("="*60)
        print(result['final_review'])
        return result['final_review']
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì •")
        print("2. ë˜ëŠ” Ollama ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©")
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
    ğŸŒŸ ê°„ë‹¨í•œ LangGraph ì›Œí¬í”Œë¡œìš° ì˜ˆì œ
    =====================================

    Function calling ì—†ì´ ì‘ë™í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.
    ê° ë…¸ë“œëŠ” ë‹¨ìˆœíˆ LLMì„ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """)

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nëŒ€ì•ˆ:")
        print("1. .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì •")
        print("2. config.pyì—ì„œ Ollama ëª¨ë¸ë¡œ ë³€ê²½")
        return

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    products = [
        "ìƒ¤ì˜¤ë¯¸ ë¡œë´‡ì²­ì†Œê¸°",
        "ì—ì–´íŒŸ í”„ë¡œ 2",
        "ìŠ¤íƒ€ë²…ìŠ¤ í…€ë¸”ëŸ¬"
    ]

    print("í…ŒìŠ¤íŠ¸í•  ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”:")
    for i, product in enumerate(products, 1):
        print(f"{i}. {product}")

    choice = input("\nì„ íƒ (1-3, ë˜ëŠ” ì§ì ‘ ì…ë ¥): ").strip()

    if choice in ["1", "2", "3"]:
        product = products[int(choice) - 1]
    else:
        product = choice if choice else products[0]

    # ë¦¬ë·° ìƒì„±
    run_simple_review(product)


if __name__ == "__main__":
    main()